{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 32-bit",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "20f95363be5b36a5aabe57aa87d9375889937fbf7f4cb55da98b36bda841e720"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from random import random\n",
    "from random import randint\n",
    "import re\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gram:\n",
    "    def __init__(self, patterns, beforenum, afternum):\n",
    "\n",
    "        if type(patterns) == str:\n",
    "            patterns = [patterns]\n",
    "\n",
    "        self.patterns = patterns\n",
    "        self.patterns.sort()\n",
    "        self.beforearray = np.array([dict() for _ in range(beforenum)])\n",
    "        self.afterarray = np.array([dict() for _ in range(afternum)])\n",
    "        randval = random()\n",
    "        self.hashval = hash(str(self.patterns) + str(randval))\n",
    "        self.num_entries = 0\n",
    "\n",
    "    \n",
    "    def addGram(self, gram, pos):\n",
    "        \"\"\"\n",
    "        gram        - gram being read from text material\n",
    "        pos         - position relative to this gram (0 is invalid here)\n",
    "        \"\"\"\n",
    "        if pos > 0:\n",
    "            if pos < len( self.afterarray ):\n",
    "                self.afterarray[-pos].setdefault(gram,0)\n",
    "                self.afterarray[-pos][gram] += 1\n",
    "                self.num_entries += 1\n",
    "            else:\n",
    "                raise ValueError(f\"pos ({pos}) is out of range of {self}.afterarray which is of length {len(self.afterarray)}\")\n",
    "        elif pos < 0:\n",
    "            if pos < len( self.beforearray ):\n",
    "                self.beforearray[pos].setdefault(gram,0)\n",
    "                self.beforearray[pos][gram] += 1\n",
    "                self.num_entries += 1\n",
    "            else:\n",
    "                raise ValueError(f\"pos ({pos}) is out of range of {self}.beforearray which is of length {len(self.beforearray)}\")\n",
    "        else:\n",
    "            raise ValueError(\"pos cannot be 0\")\n",
    "    \n",
    "    def getStatsForPosition(self, pos):\n",
    "        if pos > 0:\n",
    "            if pos < len( self.afterarray ):\n",
    "                return( self.afterarray[-pos] )\n",
    "            else:\n",
    "                raise ValueError(f\"pos ({-pos}) is out of range of {self}.afterarray which is of length {len(self.afterarray)}\")\n",
    "        elif pos < 0:\n",
    "            if pos < len( self.beforearray ):\n",
    "                return( self.beforearray[pos] )\n",
    "            else:\n",
    "                raise ValueError(f\"pos ({pos}) is out of range of {self}.beforearray which is of length {len(self.beforearray)}\")\n",
    "        else:\n",
    "            raise ValueError(\"pos cannot be 0\")\n",
    "\n",
    "    def matchPattern(self, s):\n",
    "        \"\"\"\n",
    "        s   - a string\n",
    "        returns the length of the matching pattern if there is a match\n",
    "        else returns 0\n",
    "        \"\"\"\n",
    "        longestmatch = 0\n",
    "        for pattern in self.getPatterns():\n",
    "\n",
    "            ## truncate string s\n",
    "            str_to_match = s[:len(pattern)]\n",
    "\n",
    "            # match truncated string\n",
    "            if str_to_match == pattern:\n",
    "                if len(pattern) > longestmatch:\n",
    "                    longestmatch = len(pattern)\n",
    "        return(longestmatch)\n",
    "\n",
    "\n",
    "    def getPatterns(self):\n",
    "        return(self.patterns)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return(str(self.patterns) < str(other.patterns))\n",
    "    def __gt__(self, other):\n",
    "        return(str(self.patterns) > str(other.patterns))\n",
    "    def __lte__(self, other):\n",
    "        return(str(self.patterns) <= str(other.patterns))\n",
    "    def __gte__(self, other):\n",
    "        return(str(self.patterns) >= str(other.patterns))\n",
    "    def __eq__(self, other):\n",
    "        return(self.patterns == other.patterns)\n",
    "    def __ne__(self, other):\n",
    "        return(self.patterns != other.patterns)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return(self.hashval)\n",
    "    def __str__(self):\n",
    "        s = '<Gram: \"'\n",
    "        s += str(self.patterns)\n",
    "        s += '\" hash: '\n",
    "        s += str(self.__hash__())\n",
    "        s += ' entries: '\n",
    "        s += str(self.num_entries)\n",
    "        s += \">\"\n",
    "        return(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramData:\n",
    "    def __init__(self, beforenum, afternum):\n",
    "        self.allgrams = dict()\n",
    "        self.allgrams_by_pattern = dict()\n",
    "        self.beforenum = beforenum\n",
    "        self.afternum = afternum\n",
    "        self.emptygram = Gram(\"<EMPTY_GRAM>\", self.beforenum, self.afternum)\n",
    "        self.defaultStartGram = Gram(\"<DEFAULT_START_GRAM>\", self.beforenum, self.afternum)\n",
    "        self.defaultEndGram = Gram(\"<DEFAULT_END_GRAM>\", self.beforenum, self.afternum)\n",
    "    \n",
    "    def addGram(self, gram):\n",
    "        self.allgrams.setdefault(gram, 0)\n",
    "        #self.allgrams[gram] += 1\n",
    "\n",
    "        for pattern in gram.getPatterns():\n",
    "            self.allgrams_by_pattern.setdefault(pattern,set())\n",
    "            self.allgrams_by_pattern[pattern].add(gram)\n",
    "\n",
    "    def incGramCount(self, gram):\n",
    "        self.allgrams.setdefault(gram, 0)\n",
    "        self.allgrams[gram] += 1\n",
    "\n",
    "        #for pattern in gram.getPatterns():\n",
    "        #    self.allgrams_by_pattern.setdefault(pattern,set())\n",
    "        #    self.allgrams_by_pattern[pattern].add(gram)\n",
    "\n",
    "    def readGramSequence(self, gramSequence, startgram = None, endgram = None):\n",
    "        if startgram == None:\n",
    "            startgram = self.defaultStartGram\n",
    "        if endgram == None:\n",
    "            endgram = self.defaultEndGram\n",
    "        \n",
    "        for i,gram in enumerate(gramSequence):\n",
    "            self.incGramCount(gram)\n",
    "            \n",
    "            ## before gram\n",
    "            for pos in range(-1, self.beforenum, -1):\n",
    "                i_before = i + pos\n",
    "                if i_before < -1:\n",
    "                    beforegram = self.emptygram\n",
    "                elif i_before == -1:\n",
    "                    beforegram = startgram\n",
    "                else:\n",
    "                    beforegram = gramSequence[i_before]\n",
    "                gram.addGram(beforegram, pos)\n",
    "\n",
    "            ## after gram\n",
    "            for pos in range(1, self.afternum, 1):\n",
    "                i_after = i + pos\n",
    "                if i_after > len(gramSequence):\n",
    "                    aftergram = self.emptygram\n",
    "                elif i_after == len(gramSequence):\n",
    "                    aftergram = endgram\n",
    "                else:\n",
    "                    aftergram = gramSequence[i_after]\n",
    "                gram.addGram(aftergram, pos)\n",
    "\n",
    "    def tokenizeString(self, s):\n",
    "        token_sequence = []\n",
    "        i=0\n",
    "        while i < len(s):\n",
    "            #print(i)\n",
    "            #print(s[i])\n",
    "            longestmatch_gram = None\n",
    "            longestmatch = 0\n",
    "            for gram in self.allgrams.keys():\n",
    "                \n",
    "                result = gram.matchPattern(s[i:])\n",
    "#                print(gram)\n",
    "                if result > 0:\n",
    "                    if result > longestmatch:\n",
    "                        longestmatch_gram = gram\n",
    "                        longestmatch = result\n",
    "            if longestmatch == 0:\n",
    "                longestmatch = 1\n",
    "                longestmatch_gram = Gram(s[i], self.beforenum, self.afternum)\n",
    "                self.addGram(longestmatch_gram)\n",
    "\n",
    "            i += longestmatch\n",
    "            token_sequence.append(longestmatch_gram)\n",
    "\n",
    "        return(token_sequence)\n",
    "\n",
    "    \n",
    "    def tokenizeTextBasic(self, s):\n",
    "        gramSequence = []\n",
    "\n",
    "        allchars = set(s)\n",
    "        local_allgrams_by_pattern = dict()\n",
    "        for character in allchars:\n",
    "            if character in local_allgrams_by_pattern:\n",
    "                continue\n",
    "            elif character in self.allgrams_by_pattern:\n",
    "                local_allgrams_by_pattern[character] = list(self.allgrams_by_pattern[character])[0]  ## this won't work with multiple patterns with the same pattern\n",
    "                if len(self.allgrams_by_pattern[character]) > 1:\n",
    "                    warn(f\"tokenizeTextBasic: there are multiple grams for pattern '{character}'\")\n",
    "            else:\n",
    "                local_allgrams_by_pattern[character] = Gram(character, self.beforenum, self.afternum)\n",
    "\n",
    "        for character in s:\n",
    "            gramSequence.append( local_allgrams_by_pattern[character] )\n",
    "\n",
    "        return(gramSequence)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gd = GramData(5,5)\n",
    "gramSequence = gd.tokenizeString(\"here is a cat and here it is again\")\n",
    "gd.readGramSequence(gramSequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<Gram: \"['h']\" hash: 2020856964 entries: 8>:2\n<Gram: \"['e']\" hash: 513820499 entries: 16>:4\n<Gram: \"['r']\" hash: -506551348 entries: 8>:2\n<Gram: \"[' ']\" hash: 2038929698 entries: 32>:8\n<Gram: \"['i']\" hash: -1494704369 entries: 16>:4\n<Gram: \"['s']\" hash: 2084596253 entries: 8>:2\n<Gram: \"['a']\" hash: 1132832397 entries: 20>:5\n<Gram: \"['c']\" hash: -1899141315 entries: 4>:1\n<Gram: \"['t']\" hash: -638609257 entries: 8>:2\n<Gram: \"['n']\" hash: -312730298 entries: 8>:2\n<Gram: \"['d']\" hash: 1809122505 entries: 4>:1\n<Gram: \"['g']\" hash: -1945577307 entries: 4>:1\n"
    }
   ],
   "source": [
    "for gram,count in gd.allgrams.items():\n",
    "    print(f\"{gram}:{count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<Gram: \"['h']\" hash: 88354605 entries: 8>\n<Gram: \"['e']\" hash: 1572867462 entries: 16>\n<Gram: \"['r']\" hash: -3166736 entries: 8>\n<Gram: \"['e']\" hash: 1572867462 entries: 16>\n<Gram: \"[' ']\" hash: 1795449775 entries: 32>\n<Gram: \"['i']\" hash: 1212407449 entries: 16>\n<Gram: \"['s']\" hash: 1577366684 entries: 8>\n<Gram: \"[' ']\" hash: 1795449775 entries: 32>\n<Gram: \"['a']\" hash: 666374999 entries: 20>\n<Gram: \"[' ']\" hash: 1795449775 entries: 32>\n<Gram: \"['c']\" hash: -1232861293 entries: 4>\n<Gram: \"['a']\" hash: 666374999 entries: 20>\n<Gram: \"['t']\" hash: 112387569 entries: 8>\n<Gram: \"[' ']\" hash: 1795449775 entries: 32>\n<Gram: \"['a']\" hash: 666374999 entries: 20>\n<Gram: \"['n']\" hash: 1480122275 entries: 8>\n<Gram: \"['d']\" hash: -2071129317 entries: 4>\n<Gram: \"[' ']\" hash: 1795449775 entries: 32>\n<Gram: \"['h']\" hash: 88354605 entries: 8>\n<Gram: \"['e']\" hash: 1572867462 entries: 16>\n<Gram: \"['r']\" hash: -3166736 entries: 8>\n<Gram: \"['e']\" hash: 1572867462 entries: 16>\n<Gram: \"[' ']\" hash: 1795449775 entries: 32>\n<Gram: \"['i']\" hash: 1212407449 entries: 16>\n<Gram: \"['t']\" hash: 112387569 entries: 8>\n<Gram: \"[' ']\" hash: 1795449775 entries: 32>\n<Gram: \"['i']\" hash: 1212407449 entries: 16>\n<Gram: \"['s']\" hash: 1577366684 entries: 8>\n<Gram: \"[' ']\" hash: 1795449775 entries: 32>\n<Gram: \"['a']\" hash: 666374999 entries: 20>\n<Gram: \"['g']\" hash: 1638319628 entries: 4>\n<Gram: \"['a']\" hash: 666374999 entries: 20>\n<Gram: \"['i']\" hash: 1212407449 entries: 16>\n<Gram: \"['n']\" hash: 1480122275 entries: 8>\n"
    }
   ],
   "source": [
    "for gram in gramSequence:\n",
    "    print(gram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"['cat']\""
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "str(['cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}